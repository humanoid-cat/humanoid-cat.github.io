<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A minimalist RL architecture for humanoid locomotion and loco-manipulation.">
  <meta name="keywords" content="CaT, Reinforcement Learning, Legged Locomotion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning Humanoid Loco-manipulation with Constraints as Terminations</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/laasicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Learning Humanoid Loco-manipulation with Constraints as Terminations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://paleziart.github.io/">Pierre-Alexandre Leziart</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Mitsuharu Morisawa</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Fumio Kanehiro</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> CNRS-AIST JRL (Joint Robotics Laboratory), Japan</span>
          </div>

           <!-- TODO UPDATE LINKS -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.18765.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2403.18765"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!--<span class="link-block">
                <a href="https://www.youtube.com/watch?v=V5CwV2peNUw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/gepetto/constraints-as-terminations"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->

              <!-- Dataset Link. -->
              <!-- 
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        WEBSITE UNDER CONSTRUCTION
      </h2>
    </div>
  </div>
</section> -->

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/parkour_no_audio_480p.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">CaT</span> enables agile locomotion over a wide range of challenging terrains </br> while satisfying safety and style constraints.
      </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deep Reinforcement Learning (RL) is now commonly used for controlling legged robots. 
            Several recent studies have demonstrated impressive results in solving increasingly complex robotic tasks such as navigation in unstructured environments or loco-manipulation. 
            However, this complexity often comes with intricate learning setups requiring tedious reward shaping and features to help convergence. 
          </p>
          <p>
            In this work, we tackle these issues and achieve loco-manipulation with a humanoid robot using a RL algorithm that enforces constraints through stochastic terminations during policy learning. 
            We keep the number of rewards low by reformulating them as constraints when they can be intuitively expressed that way. 
            Moreover, we study the relevance of various learning features encountered in the literature and show that providing observations without noise or privileged information to the critic are two straightforward ways to boost locomotion performances on rough terrains. 
            We also demonstrate that the proposed minimalist architecture is not limited to pure locomotion but extends to a loco-manipulation task involving upper limbs. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/watch?v=V5CwV2peNUw"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<!-- Simulation VS Real. -->
<section class="section">
  <div class="container is-max-desktop">

    <!-- Training for blind locomotion on rough terrain. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Training for blind locomotion on rough terrain</h2>
        <div class="content has-text-justified">
          <p>
            We leverage <a href="https://constraints-as-terminations.github.io/">Constraints as Terminations</a> to perform a velocity tracking task on rough terrain while satisfying safety and style constraints. 
            Observations include the measured positions and velocities of the 10 lower joints of the robot (5 per leg), the previous action, the waist angular velocity, the gravity vector projected in waist frame, central phases for each leg defined as cosine and sine pairs, and the linear and angular velocity command that the robot must track. 
            Central phases are used to guide leg motion toward a desired gait pattern.
            The action space consists of the desired joint position offsets with respect to a default joint configuration. The resulting target position is then converted into torques through a low level proportional-derivative controller. 
            We train policies with a curriculum on the terrain difficulty using Isaac Gym.
          </p>
        </div>

        <!-- Side by side videos. -->
        <div class="columns is-centered">
          <!-- Walking on rough terrain. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/task_vel_tracking.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          <!-- Terrain curriculum. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/training_curriculum.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Training for blind locomotion on rough terrain. -->

    <!-- Training for loco-manipulation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3"  style="padding-top:1em">Training for loco-manipulation</h2>
        <div class="content has-text-justified">
          <p>
            We extend our RL scheme to humanoid loco-manipulation for transporting a package in simulation. 
            Most of the constraints from the blind locomotion are kept and the velocity commands is replaced by observations about the box and the target location.
          </p>
        </div>

        <div class="columns is-centered">
          <video id="dollyzoom" autoplay controls muted loop playsinline width="60%">
            <source src="./static/videos/task_box_transport.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Side by side paragraphs. -->
        <div class="columns is-centered">
          <!-- Left column. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content has-text-justified">
                <p>
                  For simplicity, the robot starts in a position for which the package is placed between its hands. 
                  This eases the pick-up procedure compared to more extensive works where the robot has to get into position first.
                </p>
              </div>
            </div>
          </div>
          <!-- Right column. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content has-text-justified">
                <p>
                  The goal is to release the package atop another 90 cm pillar placed randomly in a half circle behind the robot with a radius of 1.5 m.
                </p>
              </div>
            </div>
          </div>
        </div>

        <!-- Side by side pictures. -->
        <div class="columns is-centered">
          <!-- Left column. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <img src="./static/images/cube_initial.png"/>
              </div>
            </div>
          </div>
          <!-- Right column. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <img src="./static/images/skyeye.png"/>
              </div>
            </div>
          </div>
        </div>

        <h2 class="title is-3" style="padding-top:1em">Transport over longer distances</h2>

        <!-- Side by side videos. -->
        <div class="content has-text-justified">
          <p>
            The package transport can be seamlessly extended to longer distances even if training was only done for a short one. 
            To do so, we scale down the goal distance in the observations to go back to the training situation.
            The robot can handle push disturbances even when transporting the box, as seen on the right video in the middle of the trajectory.
          </p>
        </div>
        <div class="columns is-centered">
          <!-- Walking on rough terrain. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/box_d6.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          <!-- Terrain curriculum. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/box_d10_push.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>

        <div class="content has-text-justified">
          <p>
            Going further, we can also achieve long distance navigation, including turns during transport, by regularly modifying the goal position to guide the robot along a path.
          </p>
        </div>
        <div class="columns is-centered">
          <video id="dollyzoom" autoplay controls muted loop playsinline width="60%">
            <source src="./static/videos/transport_navigation.mp4"
                    type="video/mp4">
          </video>
        </div>

        <h2 class="title is-3" style="padding-top:1em">Changing the size of the package</h2>

        <!-- Side by side videos. -->
        <div class="content has-text-justified">
          <p>
            The robot can consistently transport smaller packages as well, here with a 15 centimeters box instead of the default 25 centimeters one.
            However, although it can transport them, the robot struggles to properly release bigger packages at the goal location as it does not open the arms wide enough. 
          </p>
        </div>
        <div class="columns is-centered">
          <!-- Walking on rough terrain. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/box_small.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          <!-- Terrain curriculum. -->
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/box_big.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>

      
      </div>
    </div>
    <!--/ Training for loco-manipulation. -->

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{chanesane2024cat,
      title={CaT: Constraints as Terminations for Legged Locomotion Reinforcement Learning},
      author={Elliot Chane-Sane and Pierre-Alexandre Leziart and Thomas Flayols and Olivier Stasse and Philippe Souères and Nicolas Mansard},
      year={2024},
      eprint={2403.18765},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}</code></pre>
  </div>
</section> -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a> --> <!-- TODO LINK -->
      <a class="icon-link" href="https://github.com/humanoid-cat/humanoid-cat.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a> for sharing their template.
          </p>
          <p>
            You are free to borrow the <a href="https://github.com/humanoid-cat/humanoid-cat.github.io">source code</a> <!-- TODO LINK -->
            of this website, we just ask that you link back to this page in the footer, as well as to
            <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
